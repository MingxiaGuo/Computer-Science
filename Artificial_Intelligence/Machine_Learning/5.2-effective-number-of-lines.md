如果我们回顾一下Hoeffding不等式推导的过程，
![](/assets/图59.PNG)
就会发现不等式右边求解的是一个概率上限，是将M种hypothesis坏事件发生的概率直接加和得到的结果。仔细想一下，如果两条直线很接近，那么他们出现坏事件的情况是会overlap的，所以直接加和的结果是over-estimate的。这样看来，针对M是无限的情况，我们有必要将hypothesis set进行分类，从而得到更准确的概率上限。

很明显，训练数据是有限的，尽管hypothesis set中有无限多条线，但是可以按照对训练数据分类情况进行分类。举个例子，当训练数据只有1个时，无限的hypothesis set中就只有两类：1类将其分为+1，另一类将其分为-1；同理，当训练数据只有2个时，无限的hypothesis set中就只有4类。当训练数据只有3个时呢，初步看起来好像是8个，真的如此吗？考虑如下一种特殊的情况：

![](assets/图60.png)
图 输入为2个点，对应4个点，4个假设
![](assets/图63.jpg)
图 输入为3个点对应的线条数，第三行的两个是无法用一条直线分类出来的。

![](assets/图64.jpg)
图 输入为4个点对应的线条数，右边第三种无法划出一条线。


下图是线条分类结果，也对应一个h
![](assets/图65.png)
结论：对于不用的输入，最终得到的hypothesis set数量是有限的(effective number of lines)。一个点的时候只有2种线条，2个对应4种线条，3个式8，4个点是14。总的来说H的数量小于$$2^N$$，Hoeffding不等式的右边的M为无限的时候没法处理，那是因为存在过估计，我们是否能用一个有限的代替它，从而转化为有限的情况。

对于N大小的训练数据，超平面有效的种类数量是有限的，肯定小于2N个，那么我们就可以用这个有限的种类数量来代替原来Hoeffding不等式右边无限的M，如下所示：
![](assets/图66.jpg)
