# TCP

TCP: Transmission Control Protocol, 传输控制协议

它天然认为网络环境是恶劣的，丢包、乱序、重传，拥塞都是常有的事情，一言不合就可能送达不了，因而要从算法层面来保证可靠性。

在公网上传输数据，公网往往是不可靠的，因而需要很多的机制去保证传输的可靠性，这里面需要恒心，也即各种**重传的策略**，还需要有智慧，也就是说，这里面包含着**大量的算法**

## 5.3.1 TCP 特点

* 面向连接的运输层协议
* 每条TCP连接只能有两个端点
* 提供可靠交付
* 提供全双工通信
* **面向字节流**

## 5.5-TCP报文段的首部格式

TCP segment structure

TCP是靠谱的协议，但是这不能说明它面临的网络环境好。从IP层面来讲，如果网络状况的确那么差，是没有任何可靠性保证的，而作为IP的上一层TCP也无能为力，唯一能做的就是更加努力，不断重传，通过各种算法保证。也就是说，对于TCP来讲，IP层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性。

![a795461effcce686a43f48e094c9adbf](https://static001.geekbang.org/resource/image/a7/bf/a795461effcce686a43f48e094c9adbf.jpg)

* **源端口号**和**目标端口号**：是不可少的，和UDP是一样的。如果没有这两个端口号。数据就不知道应该发给哪个应用。

* 包的**序号**。为了**解决乱序的问题**。不编好号怎么确认哪个应该先来，哪个应该后到呢。

* **确认序号**。发出去的包应该有确认，要不然我怎么知道对方有没有收到呢？如果没有收到就应该重新发送，直到送达。这个可以**解决不丢包的问题**。

* 状态位。例如；TCP是面向连接的，因而双方要**维护连接的状态**，这些带状态位的包的发送，会引起双方的状态变更。
  * **SYN**是发起一个连接，
  * **ACK**是回复，
  * **RST**是重新连接，
  * **FIN**是结束连接等。

* **窗口大小**。TCP要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。

-----

通过对TCP头的解析，我们知道要掌握TCP协议，重点应该关注以下几个问题：

- 顺序问题 ，稳重不乱；
- 丢包问题，承诺靠谱；
- 连接维护，有始有终；
- 流量控制，把握分寸；
- 拥塞控制，知进知退。

- TCP包头很复杂，但是主要关注五个问题，顺序问题，丢包问题，连接维护，流量控制，拥塞控制；

## 5.3.2 TCP 的连接管理

包最终都是通过链路层、物量层这样子一个一个出去的，所以连接只是一种逻辑术语，并不存在像管道那样子的东西，连接在这里相当于双方一种约定，双方按说好的规矩维护状态。连接是一种状态，建立连接是维持一种状态，维持状态通过一定的数据结构来完成

**TCP是面向连接的，在计算机看来，怎么样才算一个连接呢？**:TCP连接是通过三次握手建立连接，四次挥手释放连接，这里的连接是指彼此可以感知到对方的存在，计算机两端表现为socket,有对应的接受缓存和发送缓存，有相应的拥塞控制策略。这是TCP的两端为了维护连接所保持的数据结构：五元组(协议，本机ip，本机端口，远程主机ip，运程主机端口)。

为了维护连接的状态的数据结构：

### TCP 连接建立:三次握手

TCP的连接建立，我们常常称为三次握手。

A：您好，我是A。

B：您好A，我是B。

A：您好B。

我们也常称为“**请求->应答->应答之应答**”的三个回合。

首先，为什么要三次，而不是两次？按说两个人打招呼，一来一回就可以了啊？为了可靠，为什么不是四次？

我们还是假设这个通路是非常不可靠的，A要发起一个连接，当发了第一个请求杳无音信的时候，会有很多的可能性，比如第一个请求包丢了，再如没有丢，但是绕了弯路，超时了，还有B没有响应，不想和我连接。

A不能确认结果，于是再发，再发。终于，有一个请求包到了B，但是请求包到了B的这个事情，目前A还是不知道的，A还有可能再发。

B收到了请求包，就知道了A的存在，并且知道A要和它建立连接。如果B不乐意建立连接，则A会重试一阵后放弃，连接建立失败，没有问题；**如果B是乐意建立连接的，则会发送应答包给A。**

当然对于B来说，这个应答包也是一入网络深似海，不知道能不能到达A。这个时候B自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者A已经挂了都有可能。

而且这个时候B还能碰到一个诡异的现象就是，A和B原来建立了连接，做了简单通信后，结束了连接。还记得吗？A建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B会认为这也是一个正常的的请求的话，因此建立了连接，可以想象，这个连接不会进行下去，也没有个终结的时候，纯属单相思了。因而两次握手肯定不行。

B发送的应答可能会发送多次，但是只要一次到达A，A就认为连接已经建立了，因为**对于A来讲，他的消息有去有回**。A会给B发送应答之应答，而B也在等这个消息，才能确认连接的建立，只有等到了这个消息，**对于B来讲，才算它的消息有去有回。**

当然A发给B的应答之应答也会丢，也会绕路，甚至B挂了。按理来说，还应该有个应答之应答之应答，这样下去就没底了。所以四次握手是可以的，四十次都可以，关键四百次也不能保证就真的可靠了。只要双方的消息都有去有回，就基本可以了。

好在大部分情况下，A和B建立了连接之后，A会马上发送数据的，一旦A发送数据，则很多问题都得到了解决。例如A发给B的应答丢了，当A后续发送的数据到达的时候，B可以认为这个连接已经建立，或者B压根就挂了，A发送的数据，会报错，说B不可达，A就知道B出事情了。

当然你可以说A比较坏，就是不发数据，建立连接后空着。我们在程序设计的时候，可以要求开启keepalive机制，即使没有真实的数据包，也有探活包。

另外，你作为服务端B的程序设计者，对于A这种长时间不发包的客户端，可以主动关闭，从而空出资源来给其他客户端使用。

三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是**TCP包的序号的问题**。

A要告诉B，我这面发起的包的序号起始是从哪个号开始的，B同样也要告诉A，B发起的包的序号起始是从哪个号开始的。为什么序号不能都从1开始呢？因为这样往往会出现冲突。

例如，A连上B之后，发送了1、2、3三个包，但是发送3的时候，中间丢了，或者绕路了，于是重新发送，后来A掉线了，重新连上B后，序号又从1开始，然后发送2，但是压根没想发送3，但是上次绕路的那个3又回来了，发给了B，B自然认为，这就是下一个包，于是发生了错误。

因而，**每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个32位的计数器，每4ms加一，如果计算一下，如果到重复，需要4个多小时，那个绕路的包早就死翘翘了，因为我们都知道IP包头里面有个TTL，也即生存时间**。

好了，双方终于建立了信任，建立了连接。前面也说过，**为了维护这个连接，双方都要维护一个状态机，**在连接建立的过程中，双方的**状态变化时序图**就像这样。

![img](https://static001.geekbang.org/resource/image/66/a2/666d7d20aa907d8317af3770411f5aa2.jpg)

一开始，客户端和服务端都处于CLOSED状态。先是服务端主动监听某个端口，处于LISTEN状态。然后客户端主动发起连接SYN，之后处于SYN-SENT状态。服务端收到发起的连接，返回SYN，并且ACK客户端的SYN，之后处于SYN-RCVD状态。客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为它一发一收成功了。服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收了。

### TCP连接释放:四次挥手

好了，说完了连接，接下来说一说“拜拜”，好说好散。这常被称为四次挥手。

A：B啊，我不想玩了。

B：哦，你不想玩了啊，我知道了。

这个时候，还只是A不想玩了，也即A不会再发送数据，但是B能不能在ACK的时候，直接关闭呢？当然不可以了，很有可能A是发完了最后的数据就准备不玩了，但是B还没做完自己的事情，还是可以发送数据的，所以称为**半关闭的状态**。

这个时候A可以选择不再接收数据了，也可以选择最后再接收一段数据，等待B也主动关闭。

B：A啊，好吧，我也不玩了，拜拜。

A：好的，拜拜。

这样整个连接就关闭了。但是这个过程有没有异常情况呢？当然有，上面是和平分手的场面。

A开始说“不玩了”，B说“知道了”，这个回合，是没什么问题的，因为在此之前，双方还处于合作的状态，如果A说“不玩了”，没有收到回复，则A会重新发送“不玩了”。但是这个回合结束之后，就有可能出现异常情况了，因为已经有一方率先撕破脸。

一种情况是，A说完“不玩了”之后，直接跑路，是会有问题的，因为B还没有发起结束，而如果A跑路，B就算发起结束，也得不到回答，B就不知道该怎么办了。另一种情况是，A说完“不玩了”，B直接跑路，也是有问题的，因为A不知道B是还有事情要处理，还是过一会儿会发送结束。

那怎么解决这些问题呢？TCP协议专门设计了几个状态来处理这些问题。我们来看断开连接的时候的**状态时序图**。

![img](https://static001.geekbang.org/resource/image/1f/11/1f6a5e17b34f00d28722428b7b8ccb11.jpg)

断开的时候，我们可以看到，当A说“不玩了”，就进入FIN_WAIT_1的状态，B收到“A不玩”的消息后，发送知道了，就进入CLOSE_WAIT的状态。

A收到“B说知道了”，就进入FIN_WAIT_2的状态，如果这个时候B直接跑路，则A将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fin_timeout这个参数，设置一个超时时间。

如果B没有跑路，发送了“B也不玩了”的请求到达A时，A发送“知道B也不玩了”的ACK后，从FIN_WAIT_2状态结束，按说A可以跑路了，但是最后的这个ACK万一B收不到呢？则B会重新发一个“B不玩了”，这个时候A已经跑路了的话，B就再也收不到ACK了，因而TCP协议要求A最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果B没收到ACK的话，“B说不玩了”会重发的，A会重新发一个ACK并且足够时间到达B。

**A直接跑路还有一个问题是，A的端口就直接空出来了，但是B不知道，B原来发过的很多包很可能还在路上，如果A的端口被一个新的应用占用了，这个新的应用会收到上个连接中B发过来的包**，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来B发送的所有的包都死翘翘，再空出端口来。

等待的时间设为2MSL，**MSL**是**Maximum Segment Lifetime**，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。

还有一个异常情况就是，B超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，B当然还会重发FIN，这个时候A再收到这个包之后，A就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，**于是就直接发送RST**，B就知道A早就跑了。

### TCP状态机

TCP 的有限状态机

将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的TCP的状态机。学习的时候比较建议将这个状态机和时序状态机对照着看，不然容易晕。

![img](https://static001.geekbang.org/resource/image/da/ab/dab9f6ee2908b05ed6f15f3e21be88ab.jpg)

在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端A的状态变迁，加粗的虚线是服务端B的状态变迁。





如果是建立链接了，数据传输过程链接断了，客户端和服务器端各自会是什么状态？
或者我可以这样理解么，所谓的链接根本是不存在的，双方握手之后，数据传输还是跟udp一样，只是tcp在维护顺序、流量之类的控制

是的，连接就是两端的状态维护，中间过程没有所谓的连接，一旦传输失败，一端收到消息，才知道状态的变化



流量控制和拥塞控制什么区别？一个是对另一端的，一个是针对网络的



tcp连接的断开比建立复杂一些，本质上是因为资源的申请（初始化）本身就比资源的释放简单，以c++为例，构造函数初始化对象很简单，而析构函数则要考虑所有资源安全有序的释放，tcp断连时序中除了断开这一重要动作，另外重要的潜台词是“我要断开连接了 你感觉把收尾工作做了”

### 查看TCP连接的状态

TCP 的连接有这么多的状态，你知道如何在系统中查看某个连接的状态吗？

用netstat 或者lsof命令grep一下establish listen close_wait等命令查看



问题1: 昨天阿里云出故障，恢复后，我们调用阿里云服务的时后出现了调用出异常 connection reset。netstat看了下这个ip发现都是timewait，链接不多，但是始终无法连接放对方的服务。按照今天的内容，难道是我的程序关闭主动关闭链接后没有发出最后的ack吗？之前都没有问题，很不解

答：如果处于TIMEWAIT状态，说明双方建立成功过连接，而且已经发送了最后的ACK之后，才会处于这个状态，而且是主动发起关闭的一方处于这个状态。

如果存在大量的TIMEWAIT，往往是因为短连接太多，不断的创建连接，然后释放连接，从而导致很多连接在这个状态，可能会导致无法发起新的连接。解决的方式往往是：

- 打开tcp_tw_recycle和tcp_timestamps选项；
- 打开tcp_tw_reuse和tcp_timestamps选项；
- 程序中使用SO_LINGER，应用强制使用rst关闭。

当客户端收到Connection Reset，往往是收到了TCP的RST消息，RST消息一般在下面的情况下发送：

- 试图连接一个未被监听的服务端；
- 对方处于TIMEWAIT状态，或者连接已经关闭处于CLOSED状态，或者重新监听seq num不匹配；
- 发起连接时超时，重传超时，keepalive超时；
- 在程序中使用SO_LINGER，关闭连接时，放弃缓存中的数据，给对方发送RST。



问题2: 起始序列号是怎么计算的，会冲突吗？

我们做一个基于tcp的“物联网”应用（中国移动网络），如上面所说tcp层面已经会自动重传数据了，业务层面上还有必要再重传吗？如果是的话，业务需要多久重传一次？

--- TCP的重传是网络层面和粒度的，业务层面需要看具体业务，比如发送失败可能对端在重启，一个重启时间是1min，那就没有必要每秒都发送检测啊.

1、‘序号的起始序号随时间变化，...重复需要4个多小时’，老师这个重复时间怎么计算出来的呢？每4ms加1，如果有两个TCP链接都在这个4ms内建立，是不是就是相同的起始序列号呢。
答:序号的随时间变化，主要是为了区分同一个链接发送序号混淆的问题，两个链接的话，端口或者IP肯定都不一样了.2、报文最大生存时间（MSL）和IP协议的路由条数（TTL）什么关系呢，报文当前耗时怎么计算？TCP层有存储相应时间？
答:都和报文生存有关，前者是时间维度的概念，后者是经过路由跳数，不是时间单位.

起始ISN是基于时钟的，每4毫秒加一，转一圈要4.55个小时。

TCP初始化序列号不能设置为一个固定值，因为这样容易被攻击者猜出后续序列号，从而遭到攻击。 RFC1948中提出了一个较好的初始化序列号ISN随机生成算法。

ISN = M + F (localhost, localport, remotehost, remoteport)

M是一个计时器，这个计时器每隔4毫秒加1。F是一个Hash算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值。要保证Hash算法不能被外部轻易推算得出，用MD5算法是一个比较好的选择。





老师有几个疑问：
1、当三次握手建立连接后，每次数据交互都还会ack吗？比如建立连接后，客户端发送数据包给服务器端，服务器成功收到数据包后会发送ack给客户端么？
2、如果建立连接后，客户端和服务器端没有任何数据交互，双方也不主动关闭连接，理论上这个连接会一直存在么？
3、2基础上，如果连接一直会在，双方又没有任何数据交互，若一方突然跑路了，另一方怎么知道对方已经不在了呢？在java scoket编程中，我开发客户端与服务器端代码，双方建立连接后，不发送任何数据，当我强制关闭一端时，另一端会收到一个强制关闭异常，这是如何知道对方已经强制关闭了呢？

2018-06-12 08:57

作者回复

是的，每次都ack。可以有keepalive，如果不交互，两边都不像释放，那就数据结构一直占用内存，对网络没啥影响。必须是发送数据的时候，才知道跑路的事情。你所谓的强制关是怎么关？有可能还是发送了fin的



老师再问个问题，TCP保证有序（后续到的包会等待之前的包），流量控制，拥塞机制，导致网络出现抖动时，延迟性就高，响应慢，，为什么要在应用层写重发机制，，毕竟TCP保证有序性，意义不大啊😄

2018-06-11 17:09

作者回复

应用层重试是解决应用层的错误，假设你调用一个进程，但是没调用成功，挂了，重试是给另一个进程发



我也纠结了4ms加一重复一次的时间是4个多小时的问题。
具体如下:
4ms是4微秒，等于100万分之一秒，32位无符号数的最大值是max=4294967296(注意区分有符号整数最大值)
公式如下4/1000000*max/60/60=4.772小时。

## 5.4-可靠传输原理

理想传输的两个特点 
①.传输信道不产生差错；
②.不管发送方以多快速读发送数据，接收方总来得及接收；

### 5.4.1 停止等待协议ARQ

ARQ: (Automatic Repeat request), 常称之为自动重传请求

* 基本原理: 
  * 发送方每发完一个分组就停止发送，等待对方确认，收到确认后再发送下一分组（发送分组和确认分组都无差错地按时到达，如上图(a)所示），发送方只要超过一段时间没有收到确认，就认为刚才发送的分组丢失了，因而重传，所以需要设置超时计时器。
  * 超时重传大体分以下三种情况。 
    ⑴、发送分组出错 ①.发送分组按时到达但出错了（丢弃）；②.发送分组到不了接收方；两种情况接收方都不发确认分组，如上图(b)所示；
    ⑵、发送分组无差错地按时到达，但确认分组丢失 如上图(c)所示，接收方会收到重复分组，接收方应丢弃这个重复的分组，不交付上层，再次发送确认；
    ⑶、发送分组无差错地按时到达，但确认分组超时到达 如上图(d)所示，接收方会收到重复分组，接收方应丢弃重复的分组，不交付上层，再次发送确认；
  * 使用这种确认和重传机制，可实现在不可靠的传送网络上实现可靠的传输；实现时应该注意以下3点  
    * ①.发送方发送完全组后，保留分组副本直至收到确认；
    * ②.分组和确认分组必须编号；
    * ③.超时计时器设置重传时间应当比数据在分组传输的平均往返时间长一些；
* 信道利用率 
* 停止等待协议的优点是简单，但缺点是**信道利用率太低**；

TD：发送分组的时间（精确计算时应扣除传送控制信息（如首部）的时间）；
RTT：信号在信道中的往返时间，它取决于信道；
TA：确认分组的接受时间(TA <TD) ；
上述公式的分母还应该包含接收方对信息的处理时间（很小而被或略）；
∵RTT>> TD  ∴信道利用率低，为了提高信道利用率采取流水线传输，这就需要连续ARQ协议和活动窗口协议；

### 5.4.2 连续 ARQ 协议

🌟🌟🌟🌟

为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为**累计确认**或者**累计应答**（**cumulative acknowledgment**）。

* 基本原理：发送方维持一个发送窗口，位于该窗口内的多个分组可连续发送，不必每发完一个分组就停顿下来等待对方的确认。接收方一般采用累积确认的方式，即不必对收到的分组逐个发送确认，而是对按序到达的、正确的最后一个分组发送确认，表示到这个分组为止的所有分组都已正确收到了。发送方重新发送确认以后的分组，这种重传机制叫“回退 N机制（go-back-N）”。
  若中间分组丢失，即使后面分组均正确收到，接收方也只能对丢失分组之前的分组进行确认，发送方并不知道。丢失分组后分组已正确接收，故从丢失分组起，重新发送
* 累积确认的**优点**是：容易实现。
* **缺点**是：不能向发送方反映出接收方已经正确收到的所有分组的信息，可见，通信线路质量不好时，连续ARQ会带来负面影响。  
  		
* **TCP可靠传输的具体实现需要对连续ARQ协议进行改进**（§5.5节详述）。



## 5.6-TCP可靠传输的实现

TCP 可靠通信的特征：:
1、TCP 连接的每一端都必须设有两个窗口：一个发送窗口和一个接收窗口。为了**保证不丢包**，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为**累计确认**或者**累计应答**（**cumulative acknowledgment**）。
2、TCP 的可靠传输机制用字节的**序号**进行控制：TCP 确认都是基于字节序号而，不是基于报文段。 为了**保证顺序性**，每一个包都有一个ID。在建立连接的时候，会商定起始的ID是什么，然后按照ID一个个发送。
3、TCP 两端的四个窗口经常处于动态变化之中。
4、TCP连接的往返时间 RTT 也不是固定不变的。需要使用特定的算法估算较为合理的重传时间。
为讲述方便，我们假定数据传输只在一个方向进行。



- 顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的，这其实就相当于你领导和你的工作备忘录，布置过的工作要有编号，干完了有反馈，活不能派太多，也不能太少；
- 拥塞控制是通过拥塞窗口来解决的，相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。

保证不丢包：

保证顺序性：

连接维护：实现方式是TCP连接管理的

流量控制

拥塞控制

----

对应到网络协议上，就是客户端每发送的一个包，服务器端都应该有个回复，如果服务器端超过一定的时间没有回复，客户端就会重新发送这个包，直到有回复。

这个发送应答的过程是什么样呢？可以是**上一个收到了应答，再发送下一个**。这种模式有点像两个人直接打电话，你一句，我一句。但是这种方式的缺点是效率比较低。如果一方在电话那头处理的时间比较长，这一头就要干等着，双方都没办法干其他事情。咱们在日常工作中也不是这样的，不能你交代你的下属办一件事情，就一直打着电话看着他做，而是应该他按照你的安排，先将事情记录下来，办完一件回复一件。在他办事情的过程中，你还可以同时交代新的事情，这样双方就并行了。

如果使⽤这种模式，其实需要你和你的下属就不能靠脑⼦了，⽽是要都准备⼀个本⼦，你每交代下属⼀个事情，双方的本子都要记录⼀下。

当你的下属做完⼀件事情，就回复你，做完了，你就在你的本⼦上将这个事情划去。同时你的本⼦上每件事情都有时限，如果超过了时限下属还没有回复，你就要主动重新交代⼀下：上次那件事情，你还没回复我，咋样啦？

既然多件事情可以一起处理，那就需要给每个事情编个号，防止弄错了。例如，程序员平时看任务的时候，都会看JIRA的ID，而不是每次都要描述一下具体的事情。在大部分情况下，对于事情的处理是按照顺序来的，先来的先处理，这就给应答和汇报工作带来了方便。等开周会的时候，每个程序员都可以将JIRA ID的列表拉出来，说以上的都做完了，⽽不⽤⼀个个说。

为了保证顺序性，每一个包都有一个ID。在建立连接的时候，会商定起始的ID是什么，然后按照ID一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为**累计确认**或者**累计应答**（**cumulative acknowledgment**）。

为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的ID一个个排列，根据处理的情况分成四个部分。

第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。

第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。

第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。

第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。

这里面为什么要区分第三部分和第四部分呢？没交代的，一下子全交代了不就完了吗？

这就是我们上一节提到的十个词口诀里的“**流量控制，把握分寸**”。作为项目管理人员，你应该根据以往的工作情况和这个员工反馈的能力、抗压力等，先在心中估测一下，这个人一天能做多少工作。如果工作布置少了，就会不饱和；如果工作布置多了，他就会做不完；如果你使劲逼迫，人家可能就要辞职了。

到底一个员工能够同时处理多少事情呢？在TCP里，接收端会给发送端报一个窗口的大小，叫**Advertised window**。这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。

于是，发送端需要保持下面的数据结构。

![img](https://static001.geekbang.org/resource/image/16/7b/16dcd6fb8105a1caa75887b5ffa0bd7b.jpg)

- LastByteAcked：第一部分和第二部分的分界线
- LastByteSent：第二部分和第三部分的分界线
- LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线

对于接收端来讲，它的缓存里记录的内容要简单一些。

第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。

第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。

第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。

对应的数据结构就像这样：

 ﻿﻿![img](https://static001.geekbang.org/resource/image/f7/a4/f7b1d3bc6b6d8e55f0951e82294c8ba4.jpg)

- MaxRcvBuffer：最大缓存的量；
- LastByteRead之后是已经接收了，但是还没被应用层读取的；
- NextByteExpected是第一部分和第二部分的分界线。

第二部分的窗口有多大呢？

NextByteExpected和LastByteRead的差其实是还没被应用层读取的部分占用掉的MaxRcvBuffer的量，我们定义为A。

AdvertisedWindow其实是MaxRcvBuffer减去A。

也就是：AdvertisedWindow = MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。

那第二部分和第三部分的分界线在哪里呢？NextByteExpected加AdvertisedWindow就是第二部分和第三部分的分界线，其实也就是LastByteRead加上MaxRcvBuffer。

其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。

## 顺序问题与丢包问题

接下来我们结合一个例子来看。

![img](https://static001.geekbang.org/resource/image/16/7b/16dcd6fb8105a1caa75887b5ffa0bd7b.jpg)

还是刚才的图，在发送端来看，1、2、3已经发送并确认；4、5、6、7、8、9都是发送了还没确认；10、11、12是还没发出的；13、14、15是接收方没有空间，不准备发的。

![img](https://static001.geekbang.org/resource/image/f7/a4/f7b1d3bc6b6d8e55f0951e82294c8ba4.jpg)

在接收端来看，1、2、3、4、5是已经完成ACK，但是没读取的；6、7是等待接收的；8、9是已经接收，但是没有ACK的。

发送端和接收端当前的状态如下：

- 1、2、3没有问题，双方达成了一致。
- 4、5接收方说ACK了，但是发送方还没收到，有可能丢了，有可能在路上。
- 6、7、8、9肯定都发了，但是8、9已经到了，但是6、7没到，出现了乱序，缓存着但是没办法ACK。

根据这个例子，我们可以知道，**顺序问题和丢包问题都有可能发生**，所以我们先来看**确认与重发的机制**。

假设4的确认到了，不幸的是，5的ACK丢了，6、7的数据包丢了，这该怎么办呢？

一种方法就是**超时重试**，也即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过了一定的时间，就重新尝试。但是这个超时的时间如何评估呢？这个时间不宜过短，时间必须大于往返时间**RTT**，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。

估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为**自适应重传算法**（**Adaptive Retransmission Algorithm**）。

如果过一段时间，5、6、7都超时了，就会重新发送。接收方发现5原来接收过，于是丢弃5；6收到了，发送ACK，要求下一个是7，7不幸又丢了。当7再次超时的时候，有需要重传的时候，TCP的策略是**超时间隔加倍**。**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。**两次超时，就说明网络环境差，不宜频繁反复发送。**

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

例如，接收方发现6、8、9都已经接收了，就是7没来，那肯定是丢了，于是发送三个6的ACK，要求下一个是7。客户端收到3个，就会发现7的确又丢了，不等超时，马上重发。

还有一种方式称为**Selective Acknowledgment** （**SACK**）。这种方式需要在TCP头里加一个SACK的东西，可以将缓存的地图发送给发送方。例如可以发送ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是7丢了。

### 5.6.1 以字节为单位的滑动窗口协议

TCP滑动窗口是以字节为单位的。 

**发送窗口**：可连续发送的字节范围，通常只是发送缓存的一部分；在没有收到对方确认下，发送可连续把窗口中的数据都发送出去。凡是已经发送过的数据，在未收到确认之前必须暂时保留，以便超时重传。

* 发送窗口的后沿：后面部分表示已经发送且已接收到确认；发送窗口的后沿的两种变化情况 ：

  * ①.前移：收到新的确认；

  * ②.不动：没有收到新的确认，并且对方通知的窗口大小没变；

    收到新的确认，但对方通知的窗口大小缩小了使得前沿正好不动；

* 发送窗口的前沿：前面部分表示不允许发送；

* 前沿与后沿共同确认发送窗口的位置；

* 后沿不可能后移，前沿不断前移，也可能不动；

* TCP不赞成前沿向后回缩（由于B通知的窗口大小缩小了而需要前沿回缩）；

* 描述发送窗口状态需三个指针：P1、P2、P3；

  * ①.小于P1的表示已发送并已接收到确认的部分。
  * ②.大于P3的是不允许发送的部分。
  * ③.P3－P1=发送方A的发送窗口
  * ④.P2－P1=已发送但尚未收到确认的字节数。
  * ⑤.P3－P2=允许发送但尚未发送的字节数。

发送缓存用来存放以下数据： 

* ①.发送应用程序传给发送方TCP；准备发送的数据
* ②.TCP已发送但尚未收到确认的数据。 
  发送缓存与发送窗口后沿重合。 

**接收窗口**：可连续接收的字节范围，通常只是接收缓存的一部分。

接收缓存用来暂时存放以下数据： 

* ①.按序到达的，但尚未被接收应用程序读取的数据；
* ②.不按序到达的数据；

【例题5.2】TCP可靠传输的具体实现的实例活动窗口协议简介： 
①.假设：某一时刻A的发送窗口和B的接收窗口如图5-16所示，接收窗口和发送窗口大小为20B不变；由于B只能对按序收到的数据中的最高序号给出确认，此时虽然正确地收到32和33号报文，但没收到31号报文，所以B发送的确认报文中的确认号为31（即期望收到31号报文），32和33号报文存储在B的缓存中等待31号报文；

②.A收到确认号为31号的确认报文后停止发42号报文而重传缓存中的31号报文；重传后继续发送42以后的报文直至发送窗口前沿； 
③.当B正确地收到31号报文后把31—33号报文交给主机并从缓存中删除，然后发送确认号为34号的新确认报文；同时B的接收窗口后沿移到34，前沿移到54并继续接收报文； 
④.A收到确认号为34号的新确认报文后把接收窗口后沿移到34，前沿移到54，从发送缓存中删除33号以前的报文，并继续发送42以后未发送的报文直至发送窗口前沿；（如图5-17所示）

⑤.若A的发送窗口已满（即可用窗口为0）就停止发送数据，等待新的确认（如图5-18所示）；若此后收到新的确认（假设确认号为41），则重传41号报文，并把接收窗口后沿移到41，前沿移到61，从发送缓存中删除40号以前的报文，并继续发送53以后未发送的报文直至发送窗口前沿；如此循环直至B接收完数据；

5、我们应注意三点 
   	①.发送窗口并不总是与接收方接收的窗口一样大；
②.TCP标准并未规定对不按序到达的数据如何处理，通常做法是临时存在接收窗口，等缺少的字节到达后再按序交付上层应用程序；
③.TCP要求接收方必须有积累确认功能，以减少传输开销。接收方有数据要发送时可捎带确认。但累积的时间不应该超过0.5秒；

### 5.6.2 超时重传时间的选择

TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。TCP超时计时器的超时重传时间究竟应设置多大呢？ 
1、TCP采用了一种自适应算法  
TCP保留了RTT的一个加权平均往返时间RTTs，第一次测量的RTT样本值作为RTTs的初始值，以后每测到一个RTT样本，就按下式重新计算一次RTTs：

式中，0 £ a < 1。若 a 很接近于零，表示 RTT 值更新较慢。若选择 a 接近于 1，则表示 RTT 值更新较快。RFC 2988 推荐的 a 值为 1/8，即 0.125。 
超时重传时间RTO略大于RTTs，使用下式计算：

RTTD是 RTT 的偏差的加权平均值第一次测量RTTD为RTT样本值的一半，以后按下式计算：

b 是个小于 1 的系数，其推荐值是 1/4，即 0.25
2、Karn方法和改进的Karn方法
问题若重传时间到了，但仍未收到确认，于是重传报文，经过一段时间后，收到确认，此时如何判断此确认报文是对先前发送的报文确认，还是对以后重传报文的确认？方法如下：
⑴、Karn的方法在计算RTTs时，只要报文重传了，就不采用其往返时间样本；
这样得到的加权平均RTTs和RTO就比较准确。但这引起新的问题，即若报文段时延增大了很多，超时重传时间无法更新，使重传次数增多。
⑵、改进的Karn方法报文段每重传一次，把RTO增大一些。
新的 RTO = g ´（旧的RTO) {系数 g 的典型值是 2}

### 5.6.3 选择确认 SACK



1、问题的提出接收方收到了和前面的字节流不连续的两个字节块，这些字节的序号都在接收窗口之内，接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方只发中间未收到的数据块而不要再重复发送这些已收到的数据，如何实现？

2、问题的解决办法RFC2018的规定：
⑴、如果要使用选择确认，那么双方必须都事先商定好在建立 TCP 连接时，就要在TCP 首部的选项中加上“允许 SACK”的选项。
⑵、原来首部中的“确认号字段”的用法仍然不变。只是以后在 TCP 报文段的首部中都增加了 SACK 选项，以便报告收到的不连续的字节块的边界。
⑶、由于首部选项的长度最多只有 40 字节，而指明一个边界就要用掉 4 字节，因此在选项中最多只能指明 4 个字节块的边界信息，32B，还需一个字节指明是SACK选项，一个字节指明这个选项占多少字节；
⑷、SACK文档并未指明发送方应当怎样响应SACK，因此，大多数的实现还是重传所有未被确认的数据块。

## 5.7-TCP的流量控制问题

我们再来看流量控制机制，在对于包的确认中，同时会携带一个窗口的大小。

我们先假设窗口不变的情况，窗口始终为9。4的确认来的时候，会右移一个，这个时候第13个包也可以发送了。

![img](https://static001.geekbang.org/resource/image/73/33/7339fd8973865164d25227cac206ca33.jpg)

这个时候，假设发送端发送过猛，会将第三部分的10、11、12、13全部发送完毕，之后就停止发送了，未发送可发送部分为0。

![img](https://static001.geekbang.org/resource/image/06/d2/06cc25118730fbf611eb315705420ed2.jpg)

当对于包5的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第14个包才可以发送。

![img](https://static001.geekbang.org/resource/image/bd/c3/bddb59ebbf7eecc4853cafce0bb1dcc3.jpg)

如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为0，则发送方将暂时停止发送。

我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包6确认后，窗口大小就不能再是9了，就要缩小一个变为8。

![img](https://static001.geekbang.org/resource/image/92/31/92f66b1556b76c46c669aba232d35a31.jpg)

这个新的窗口8通过6的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从9改成了8。

![img](https://static001.geekbang.org/resource/image/a7/ba/a78f5195ebf9b4f9dc4ea5a9b91e94ba.jpg)

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为0。

![img](https://static001.geekbang.org/resource/image/15/d2/150f28d9e745952f5968eff05e3f0ad2.jpg)

当这个窗口通过包14的确认到达发送端的时候，发送端的窗口也调整为0，停止发送。

![img](https://static001.geekbang.org/resource/image/30/30/3014a6a259f74b0c950bf3067581ac30.jpg)

如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止**低能窗口综合征**，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

这就是我们常说的流量控制。

### 5.7.1 利用滑动窗口实现流量控制

### 5.7.1 必须考虑传输效率







## 5.8-TCP的拥塞控制问题

TCP的拥塞控制主要来避免两种现象，**包丢失**和**超时重传**

最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，前面的**滑动窗口rwnd**是怕发送方把接收方缓存塞满，而**拥塞窗口cwnd**，是怕把网络塞满。

这里有一个公式 LastByteSent - LastByteAcked <= min {cwnd, rwnd} ，是拥塞窗口和滑动窗口共同控制发送的速度。

那发送方怎么判断网络是不是满呢？这其实是个挺难的事情，因为对于TCP协议来讲，他压根不知道整个网络路径都会经历什么，对他来讲就是一个黑盒。TCP发送包常被比喻为往一个水管里面灌水，而TCP的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽。

水管有粗细，网络有带宽，也即每秒钟能够发送多少数据；水管有长度，端到端有时延。在理想状态下，水管里面水的量=水管粗细 x 水管长度。对于到网络上，通道的容量 = 带宽 × 往返延迟。

如果我们设置发送窗口，使得发送但未确认的包为为通道的容量，就能够撑满整个管道。

![img](https://static001.geekbang.org/resource/image/db/e6/db8510541662281175803c7f9d1fcae6.jpg)

如图所示，假设往返时间为8s，去4s，回4s，每秒发送一个包，每个包1024byte。已经过去了8s，则8个包都发出去了，其中前4个包已经到达接收端，但是ACK还没有返回，不能算发送成功。5-8后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为8个包，正好等于带宽，也即每秒发送1个包，乘以来回时间8s。

如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？

我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费1s，所以到达另一端需要耗费4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。

这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们**在这些设备上加缓存**，处理不过来的在队列里面排着，这样包就不会丢失，但是**缺点是会增加时延**，这个缓存的包，4s肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。

于是TCP的拥塞控制主要来避免两种现象，**包丢失**和**超时重传**。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢？

如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子倒进去，肯定会溅出来，要一开始慢慢的倒，然后发现总能够倒进去，就可以越倒越快。这叫作慢启动。

一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认cwnd加一，两个确认cwnd加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认cwnd加一，四个确认cwnd加四，于是一次能够发送八个。可以看出这是**指数性的增长**。

涨到什么时候是个头呢？有一个值ssthresh为65535个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。

每收到一个确认后，cwnd增加1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加1/8，八个确认一共cwnd增加1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。

前面我们讲过**快速重传算法**。当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd减半为cwnd/2，然后sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

![img](https://static001.geekbang.org/resource/image/19/d2/1910bc1a0048d4de7b2128eb0f5dbcd2.jpg)

就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，TCP的拥塞控制主要来避免的两个现象都是有问题的。

**第一个问题**是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

**第二个问题**是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了**TCP BBR拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![img](https://static001.geekbang.org/resource/image/a2/4c/a2b3a5df5eca52e302b75824e4bbbd4c.jpg)

TCP的BBR听起来很牛，你知道他是如何达到这个最优点的嘛？

1 设备缓存会导致延时？
假如经过设备的包都不需要进入缓存，那么得到的速度是最快的。进入缓存且等待，等待的时间就是额外的延时。BBR就是为了避免这些问题：
充分利用带宽；降低buffer占用率。

2 降低发送packet的速度，为何反而提速了？
标准TCP拥塞算法是遇到丢包的数据时快速下降发送速度，因为算法假设丢包都是因为过程设备缓存满了。快速下降后重新慢启动，整个过程对于带宽来说是浪费的。通过packet速度-时间的图来看，从积分上看，BBR充分利用带宽时发送效率才是最高的。可以说BBR比标准TCP拥塞算法更正确地处理了数据丢包。对于网络上有一定丢包率的公网，BBR会更加智慧一点。
回顾网络发展过程，带宽的是极大地改进的，而最小延迟会受限与介质传播速度，不会明显减少。BBR可以说是应运而生。

3 BBR如何解决延时？
S1：慢启动开始时，以前期的延迟时间为延迟最小值Tmin。然后监控延迟值是否达到Tmin的n倍，达到这个阀值后，判断带宽已经消耗尽且使用了一定的缓存，进入排空阶段。
S2：指数降低发送速率，直至延迟不再降低。这个过程的原理同S1
S3：协议进入稳定运行状态。交替探测带宽和延迟，且大多数时间下都处于带宽探测阶段。





问题1，想到BBR可以根据ACK时间来判断，比如同一时刻发送了A、B、C三个包，A、B两个包10ms收到ACK，而C包20ms后收到ACK，那么就认为网络拥堵或被中间设备缓存，降低发送速度。
问题2，TCP优点在于准确到达，可靠性高，但是速度慢；UDP优点在于简单，但是不确认可达；像后端接口一般使用TCP协议，因为客户端和服务器之间会有多次交互，且请求数据要确认可达；但是如果是直播的话使用UDP会更好，管你网络咋样，反正我赶紧发，让用户等急了就不好了

### 5.8.1 拥塞控制的一般原理

### 5.8.2 几种拥塞控制方法

### 5.8.3 随机早期检测 RED

